{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 15:59:57,759] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"315.05us\", \"std\": \"679.55us\", \"calls\": 50}, \"rewarder.sleep\": {\"mean\": \"15.02ms\", \"std\": \"2.12ms\", \"calls\": 283}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"174.05us\", \"std\": \"130.38us\", \"calls\": 50}, \"reward.parsing.score\": {\"mean\": \"5.75ms\", \"std\": \"14.99ms\", \"calls\": 50}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"287.47us\", \"std\": \"489.58us\", \"calls\": 289}, \"reward.parsing.gameover\": {\"mean\": \"443.83us\", \"std\": \"626.04us\", \"calls\": 50}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"149.15us\", \"std\": \"11.75us\", \"calls\": 5}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"48.93ms\", \"std\": \"8.07ms\", \"calls\": 5}, \"rewarder.sleep.missed\": {\"mean\": \"30.80ms\", \"std\": \"14.56ms\", \"calls\": 6}, \"rewarder.frame\": {\"mean\": \"17.89ms\", \"std\": \"4.89ms\", \"calls\": 289}, \"rewarder.compute_reward\": {\"mean\": \"1.75ms\", \"std\": \"6.66ms\", \"calls\": 289}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.17993079584775107, \"std\": 0.4024387402308587, \"calls\": 289}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 45}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 45}} gauges={\"reward_parser.score.last_score\": {\"calls\": 50, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=384.81us)\n\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 15:59:57,738] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"rewarder.sleep.missed\": {\"std\": \"7.30ms\", \"calls\": 2, \"mean\": \"8.01ms\"}, \"rewarder.sleep\": {\"std\": \"1.11ms\", \"calls\": 298, \"mean\": \"15.72ms\"}, \"rewarder.compute_reward\": {\"std\": \"603.12us\", \"calls\": 300, \"mean\": \"492.76us\"}, \"rewarder.frame\": {\"std\": \"2.29ms\", \"calls\": 300, \"mean\": \"17.21ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"333.11us\", \"calls\": 300, \"mean\": \"217.86us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 300, \"mean\": 0.0}} gauges={} (export_time=252.72us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 15:59:57,739] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<873 bytes>'}\n\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 15:59:57,760] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.98s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1963 bytes>', 'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 16:59:58,233] Making new env: flashgames.DuskDrive-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 15:59:57,827] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=10.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=65954.8 vnc_pixels_ps[total]=65165.5 reward_lag=None rewarder_message_lag=None fps=57.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 15:59:58,189] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=59.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 15:59:59,860] [INFO:universe.wrappers.logger] Stats for the past 5.05s: vnc_updates_ps=24.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=189214.4 vnc_pixels_ps[total]=105104.3 reward_lag=None rewarder_message_lag=None fps=52.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:00,035] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.84ms\", \"mean\": \"588.73us\", \"calls\": 269}, \"rewarder.frame\": {\"std\": \"9.12ms\", \"mean\": \"19.46ms\", \"calls\": 269}, \"reward.parsing.gameover\": {\"std\": \"864.47us\", \"mean\": \"560.74us\", \"calls\": 117}, \"rewarder.sleep.missed\": {\"std\": \"21.08ms\", \"mean\": \"30.97ms\", \"calls\": 17}, \"reward.parsing.score\": {\"std\": \"17.56ms\", \"mean\": \"7.02ms\", \"calls\": 117}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"369.91us\", \"mean\": \"230.97us\", \"calls\": 117}, \"score.crop_cache.get.MatchImage\": {\"std\": \"644.29us\", \"mean\": \"267.75us\", \"calls\": 117}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"931.81us\", \"mean\": \"497.60us\", \"calls\": 15}, \"rewarder.sleep\": {\"std\": \"2.57ms\", \"mean\": \"14.10ms\", \"calls\": 252}, \"rewarder.compute_reward\": {\"std\": \"12.29ms\", \"mean\": \"4.44ms\", \"calls\": 269}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"18.21ms\", \"mean\": \"50.28ms\", \"calls\": 14}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5631117325019633, \"mean\": 0.46840148698884765, \"calls\": 269}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 102}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 103}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 117}} (export_time=2.80ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:00,037] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1963 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:00,107] [INFO:universe.wrappers.logger] Stats for the past 5.04s: vnc_updates_ps=25.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=212636.5 vnc_pixels_ps[total]=113040.9 reward_lag=None rewarder_message_lag=None fps=53.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:00,277] [INFO:root] [Rewarder] Rewarder fell behind by 0.10386943817138672s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:00,483] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.compute_reward\": {\"std\": \"16.46ms\", \"calls\": 257, \"mean\": \"4.91ms\"}, \"rewarder.sleep.missed\": {\"std\": \"34.07ms\", \"calls\": 16, \"mean\": \"45.78ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"442.39us\", \"calls\": 109, \"mean\": \"253.59us\"}, \"reward.parsing.gameover\": {\"std\": \"772.20us\", \"calls\": 109, \"mean\": \"542.59us\"}, \"rewarder.frame\": {\"std\": \"13.91ms\", \"calls\": 257, \"mean\": \"20.49ms\"}, \"rewarder.sleep\": {\"std\": \"2.58ms\", \"calls\": 241, \"mean\": \"14.36ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"27.35ms\", \"calls\": 12, \"mean\": \"69.08ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.77ms\", \"calls\": 257, \"mean\": \"487.25us\"}, \"reward.parsing.score\": {\"std\": \"23.38ms\", \"calls\": 109, \"mean\": \"8.57ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"262.58us\", \"calls\": 109, \"mean\": \"217.32us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"175.55us\", \"calls\": 13, \"mean\": \"247.48us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.5650477322215495, \"calls\": 257, \"mean\": 0.4552529182879378}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 96, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 97, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 109, \"mean\": 2954.0}} (export_time=992.06us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:00,489] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1963 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:00,973] [INFO:root] [Rewarder] Rewarder fell behind by 0.10213828086853027s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:01,168] [INFO:root] [Rewarder] Rewarder fell behind by 0.10839462280273438s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:02,211] [INFO:root] [Rewarder] Rewarder fell behind by 0.10844278335571289s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:02,742] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep.missed\": {\"std\": \"0.00us\", \"calls\": 1, \"mean\": \"2.65ms\"}, \"rewarder.sleep\": {\"std\": \"1.08ms\", \"calls\": 299, \"mean\": \"15.46ms\"}, \"rewarder.compute_reward\": {\"std\": \"1.07ms\", \"calls\": 300, \"mean\": \"714.44us\"}, \"rewarder.frame\": {\"std\": \"909.90us\", \"calls\": 300, \"mean\": \"17.05ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.06ms\", \"calls\": 300, \"mean\": \"359.35us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 300, \"mean\": 0.0}} gauges={} (export_time=291.11us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:02,760] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"194.35us\", \"std\": \"30.14us\", \"calls\": 23}, \"rewarder.sleep\": {\"mean\": \"15.49ms\", \"std\": \"1.18ms\", \"calls\": 300}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"206.02us\", \"std\": \"46.62us\", \"calls\": 23}, \"reward.parsing.score\": {\"mean\": \"787.63us\", \"std\": \"347.16us\", \"calls\": 23}, \"reward.parsing.gameover\": {\"mean\": \"388.60us\", \"std\": \"78.93us\", \"calls\": 23}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"290.93us\", \"std\": \"514.09us\", \"calls\": 300}, \"rewarder.frame\": {\"mean\": \"16.97ms\", \"std\": \"976.33us\", \"calls\": 300}, \"rewarder.compute_reward\": {\"mean\": \"740.95us\", \"std\": \"649.00us\", \"calls\": 300}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.07666666666666676, \"std\": 0.26650636207348033, \"calls\": 300}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 23}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 23}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=432.49us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:02,743] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<851 bytes>'}\n\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:02,763] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1581 bytes>', 'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:02,846] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=4.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=6440.9 vnc_pixels_ps[total]=47852.0 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:03,194] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=59.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:04,874] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=20.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=145039.3 vnc_pixels_ps[total]=90443.2 reward_lag=None rewarder_message_lag=None fps=51.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:04,945] [0] Creating container: image=quay.io/openai/universe.flashgames:0.20.21. Run the same thing by hand as: docker run -p 5905:5900 -p 15905:15900 --cap-add SYS_ADMIN --ipc host --privileged quay.io/openai/universe.flashgames:0.20.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:05,041] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"956.56us\", \"mean\": \"438.41us\", \"calls\": 232}, \"rewarder.frame\": {\"std\": \"18.08ms\", \"mean\": \"22.66ms\", \"calls\": 232}, \"reward.parsing.gameover\": {\"std\": \"2.02ms\", \"mean\": \"939.27us\", \"calls\": 91}, \"rewarder.sleep.missed\": {\"std\": \"26.16ms\", \"mean\": \"59.30ms\", \"calls\": 19}, \"reward.parsing.score\": {\"std\": \"31.10ms\", \"mean\": \"15.45ms\", \"calls\": 91}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"928.51us\", \"mean\": \"359.03us\", \"calls\": 91}, \"score.crop_cache.get.MatchImage\": {\"std\": \"629.80us\", \"mean\": \"358.07us\", \"calls\": 91}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"1.48ms\", \"mean\": \"578.43us\", \"calls\": 19}, \"rewarder.sleep\": {\"std\": \"2.69ms\", \"mean\": \"13.85ms\", \"calls\": 213}, \"rewarder.compute_reward\": {\"std\": \"21.21ms\", \"mean\": \"7.51ms\", \"calls\": 232}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"21.66ms\", \"mean\": \"76.02ms\", \"calls\": 17}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5853743110543834, \"mean\": 0.4396551724137931, \"calls\": 232}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 72}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 74}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 91}} (export_time=646.35us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:05,045] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1960 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:05,116] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=20.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=186483.6 vnc_pixels_ps[total]=104197.6 reward_lag=None rewarder_message_lag=None fps=46.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:05,492] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.compute_reward\": {\"std\": \"15.87ms\", \"calls\": 261, \"mean\": \"4.72ms\"}, \"rewarder.sleep.missed\": {\"std\": \"34.29ms\", \"calls\": 13, \"mean\": \"50.55ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"205.88us\", \"calls\": 95, \"mean\": \"239.15us\"}, \"reward.parsing.gameover\": {\"std\": \"2.41ms\", \"calls\": 95, \"mean\": \"1.04ms\"}, \"rewarder.frame\": {\"std\": \"13.21ms\", \"calls\": 261, \"mean\": \"20.29ms\"}, \"rewarder.sleep\": {\"std\": \"2.99ms\", \"calls\": 248, \"mean\": \"13.73ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"10.14ms\", \"calls\": 8, \"mean\": \"88.41ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.30ms\", \"calls\": 261, \"mean\": \"522.51us\"}, \"reward.parsing.score\": {\"std\": \"24.86ms\", \"calls\": 95, \"mean\": \"8.63ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"1.08ms\", \"calls\": 95, \"mean\": \"464.47us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"80.43us\", \"calls\": 8, \"mean\": \"239.94us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.5641829377674445, \"calls\": 261, \"mean\": 0.4022988505747129}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 87, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 87, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 95, \"mean\": 2954.0}} (export_time=764.37us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:05,514] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1952 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:05,554] [INFO:root] [Rewarder] Rewarder fell behind by 0.1154489517211914s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:05 [info] 65#65: *38 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:05 [info] 65#65: *39 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:05 [info] 65#65: *40 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:05 [info] 65#65: *41 client timed out (110: Connection timed out) while waiting for request, client: 127.0.0.1, server: 0.0.0.0:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:07,758] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"265.34us\", \"calls\": 301, \"mean\": \"237.68us\"}, \"rewarder.sleep\": {\"std\": \"1.02ms\", \"calls\": 301, \"mean\": \"15.66ms\"}, \"rewarder.compute_reward\": {\"std\": \"482.01us\", \"calls\": 301, \"mean\": \"577.53us\"}, \"rewarder.frame\": {\"std\": \"849.01us\", \"calls\": 301, \"mean\": \"16.97ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 301, \"mean\": 0.0}} gauges={} (export_time=210.29us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:07,759] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<752 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:07,776] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"191.89us\", \"std\": \"78.14us\", \"calls\": 23}, \"rewarder.sleep\": {\"mean\": \"15.17ms\", \"std\": \"1.93ms\", \"calls\": 301}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"188.37us\", \"std\": \"60.73us\", \"calls\": 23}, \"reward.parsing.score\": {\"mean\": \"689.69us\", \"std\": \"193.41us\", \"calls\": 23}, \"reward.parsing.gameover\": {\"mean\": \"572.53us\", \"std\": \"859.59us\", \"calls\": 23}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"399.49us\", \"std\": \"973.02us\", \"calls\": 301}, \"rewarder.frame\": {\"mean\": \"17.12ms\", \"std\": \"1.19ms\", \"calls\": 301}, \"rewarder.compute_reward\": {\"mean\": \"897.79us\", \"std\": \"1.32ms\", \"calls\": 301}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.0764119601328904, \"std\": 0.2660985088079444, \"calls\": 301}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 23}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 23}} gauges={\"reward_parser.score.last_score\": {\"calls\": 23, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=334.74us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:07,778] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1573 bytes>', 'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:07,861] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=4.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=5909.8 vnc_pixels_ps[total]=43906.7 reward_lag=None rewarder_message_lag=None fps=60.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:08,208] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:09,884] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=22.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=172904.4 vnc_pixels_ps[total]=98364.3 reward_lag=None rewarder_message_lag=None fps=52.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:10,044] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.89ms\", \"mean\": \"577.30us\", \"calls\": 258}, \"rewarder.frame\": {\"std\": \"12.95ms\", \"mean\": \"20.22ms\", \"calls\": 258}, \"reward.parsing.gameover\": {\"std\": \"404.68us\", \"mean\": \"413.25us\", \"calls\": 101}, \"rewarder.sleep.missed\": {\"std\": \"29.37ms\", \"mean\": \"49.47ms\", \"calls\": 14}, \"reward.parsing.score\": {\"std\": \"23.81ms\", \"mean\": \"9.07ms\", \"calls\": 101}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"618.04us\", \"mean\": \"268.44us\", \"calls\": 101}, \"score.crop_cache.get.MatchImage\": {\"std\": \"257.25us\", \"mean\": \"190.90us\", \"calls\": 101}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"29.63us\", \"mean\": \"173.27us\", \"calls\": 12}, \"rewarder.sleep\": {\"std\": \"2.50ms\", \"mean\": \"14.33ms\", \"calls\": 244}, \"rewarder.compute_reward\": {\"std\": \"15.77ms\", \"mean\": \"4.77ms\", \"calls\": 258}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"24.70ms\", \"mean\": \"67.74ms\", \"calls\": 12}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5542534938280729, \"mean\": 0.4224806201550392, \"calls\": 258}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 89}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 89}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 101}} (export_time=384.09us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:10,056] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1967 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:10,143] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=21.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=172874.1 vnc_pixels_ps[total]=99466.5 reward_lag=None rewarder_message_lag=None fps=51.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:10,505] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.compute_reward\": {\"std\": \"13.36ms\", \"calls\": 264, \"mean\": \"4.47ms\"}, \"rewarder.sleep.missed\": {\"std\": \"22.79ms\", \"calls\": 15, \"mean\": \"41.11ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"498.02us\", \"calls\": 104, \"mean\": \"242.86us\"}, \"reward.parsing.gameover\": {\"std\": \"420.02us\", \"calls\": 104, \"mean\": \"450.50us\"}, \"rewarder.frame\": {\"std\": \"10.83ms\", \"calls\": 264, \"mean\": \"20.04ms\"}, \"rewarder.sleep\": {\"std\": \"2.60ms\", \"calls\": 249, \"mean\": \"13.93ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"15.53ms\", \"calls\": 12, \"mean\": \"59.70ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.21ms\", \"calls\": 264, \"mean\": \"576.50us\"}, \"reward.parsing.score\": {\"std\": \"19.95ms\", \"calls\": 104, \"mean\": \"8.00ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"316.19us\", \"calls\": 104, \"mean\": \"229.77us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"82.69us\", \"calls\": 12, \"mean\": \"200.09us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.5600273230869961, \"calls\": 264, \"mean\": 0.42424242424242403}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 92, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 92, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 104, \"mean\": 2954.0}} (export_time=342.61us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:10,509] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.99s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1961 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:12,774] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"525.23us\", \"calls\": 301, \"mean\": \"245.77us\"}, \"rewarder.sleep\": {\"std\": \"964.35us\", \"calls\": 301, \"mean\": \"15.77ms\"}, \"rewarder.compute_reward\": {\"std\": \"573.86us\", \"calls\": 301, \"mean\": \"506.75us\"}, \"rewarder.frame\": {\"std\": \"723.59us\", \"calls\": 301, \"mean\": \"16.93ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 301, \"mean\": 0.0}} gauges={} (export_time=167.37us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:12,775] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<756 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:12,799] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"193.08us\", \"std\": \"446.76us\", \"calls\": 89}, \"rewarder.sleep\": {\"mean\": \"14.73ms\", \"std\": \"1.90ms\", \"calls\": 223}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"455.11us\", \"std\": \"1.30ms\", \"calls\": 89}, \"reward.parsing.score\": {\"mean\": \"13.56ms\", \"std\": \"24.58ms\", \"calls\": 89}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"464.76us\", \"std\": \"1.33ms\", \"calls\": 246}, \"reward.parsing.gameover\": {\"mean\": \"720.95us\", \"std\": \"1.35ms\", \"calls\": 89}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"152.37us\", \"std\": \"35.81us\", \"calls\": 23}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"54.40ms\", \"std\": \"17.28ms\", \"calls\": 21}, \"rewarder.sleep.missed\": {\"mean\": \"39.36ms\", \"std\": \"21.75ms\", \"calls\": 23}, \"rewarder.frame\": {\"mean\": \"21.03ms\", \"std\": \"13.07ms\", \"calls\": 246}, \"rewarder.compute_reward\": {\"mean\": \"6.08ms\", \"std\": \"16.42ms\", \"calls\": 246}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.410569105691057, \"std\": 0.5908572821400889, \"calls\": 246}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 66}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 68}} gauges={\"reward_parser.score.last_score\": {\"calls\": 89, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=319.96us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:12,800] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 5696, 'rewarder.profile': '<1952 bytes>', 'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 744}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:12,874] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=20.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=214574.8 vnc_pixels_ps[total]=112212.9 reward_lag=None rewarder_message_lag=None fps=49.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:13,225] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:14,901] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=24.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=212136.4 vnc_pixels_ps[total]=111887.0 reward_lag=None rewarder_message_lag=None fps=51.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:15,053] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"681.82us\", \"mean\": \"282.43us\", \"calls\": 255}, \"rewarder.frame\": {\"std\": \"12.14ms\", \"mean\": \"20.50ms\", \"calls\": 255}, \"reward.parsing.gameover\": {\"std\": \"1.28ms\", \"mean\": \"657.38us\", \"calls\": 118}, \"rewarder.sleep.missed\": {\"std\": \"19.77ms\", \"mean\": \"44.80ms\", \"calls\": 17}, \"reward.parsing.score\": {\"std\": \"21.75ms\", \"mean\": \"8.96ms\", \"calls\": 118}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"503.83us\", \"mean\": \"250.25us\", \"calls\": 118}, \"score.crop_cache.get.MatchImage\": {\"std\": \"823.81us\", \"mean\": \"314.70us\", \"calls\": 118}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"165.16us\", \"mean\": \"174.06us\", \"calls\": 18}, \"rewarder.sleep\": {\"std\": \"2.72ms\", \"mean\": \"14.23ms\", \"calls\": 238}, \"rewarder.compute_reward\": {\"std\": \"15.54ms\", \"mean\": \"5.20ms\", \"calls\": 255}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"15.43ms\", \"mean\": \"63.29ms\", \"calls\": 15}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5810288851556428, \"mean\": 0.5019607843137255, \"calls\": 255}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 100}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 103}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 118}} (export_time=557.18us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:15,054] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.99s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<1968 bytes>', 'rewarder.vnc.updates.pixels': 1840, 'rewarder.vnc.updates.bytes': 5540}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:15,147] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=25.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=208999.7 vnc_pixels_ps[total]=111439.4 reward_lag=None rewarder_message_lag=None fps=51.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:15,537] [INFO:universe.pyprofile] [pyprofile] period=5.03s timers={\"rewarder.compute_reward\": {\"std\": \"14.61ms\", \"calls\": 255, \"mean\": \"5.49ms\"}, \"rewarder.sleep.missed\": {\"std\": \"17.08ms\", \"calls\": 22, \"mean\": \"34.58ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"491.41us\", \"calls\": 116, \"mean\": \"218.54us\"}, \"reward.parsing.gameover\": {\"std\": \"1.16ms\", \"calls\": 116, \"mean\": \"526.04us\"}, \"rewarder.frame\": {\"std\": \"10.83ms\", \"calls\": 255, \"mean\": \"20.54ms\"}, \"rewarder.sleep\": {\"std\": \"2.32ms\", \"calls\": 233, \"mean\": \"14.36ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"9.83ms\", \"calls\": 18, \"mean\": \"53.42ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.95ms\", \"calls\": 255, \"mean\": \"600.54us\"}, \"reward.parsing.score\": {\"std\": \"19.80ms\", \"calls\": 116, \"mean\": \"9.02ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"398.81us\", \"calls\": 116, \"mean\": \"194.00us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"31.20us\", \"calls\": 19, \"mean\": \"146.64us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.567233548381756, \"calls\": 255, \"mean\": 0.49019607843137275}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 97, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 98, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 116, \"mean\": 2954.0}} (export_time=509.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:15,538] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.03s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1969 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:17,791] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"413.25us\", \"calls\": 301, \"mean\": \"216.92us\"}, \"rewarder.sleep\": {\"std\": \"1.23ms\", \"calls\": 301, \"mean\": \"15.73ms\"}, \"rewarder.compute_reward\": {\"std\": \"477.36us\", \"calls\": 301, \"mean\": \"492.33us\"}, \"rewarder.frame\": {\"std\": \"1.05ms\", \"calls\": 301, \"mean\": \"16.99ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 301, \"mean\": 0.0}} gauges={} (export_time=247.24us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:17,791] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<755 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:17,841] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"256.30us\", \"std\": \"466.14us\", \"calls\": 113}, \"rewarder.sleep\": {\"mean\": \"13.89ms\", \"std\": \"2.79ms\", \"calls\": 235}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"298.79us\", \"std\": \"704.54us\", \"calls\": 113}, \"reward.parsing.score\": {\"mean\": \"9.41ms\", \"std\": \"20.78ms\", \"calls\": 113}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"461.62us\", \"std\": \"959.80us\", \"calls\": 257}, \"reward.parsing.gameover\": {\"mean\": \"581.71us\", \"std\": \"1.05ms\", \"calls\": 113}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"162.51us\", \"std\": \"37.25us\", \"calls\": 19}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"55.75ms\", \"std\": \"13.31ms\", \"calls\": 17}, \"rewarder.sleep.missed\": {\"mean\": \"33.31ms\", \"std\": \"21.00ms\", \"calls\": 22}, \"rewarder.frame\": {\"mean\": \"20.76ms\", \"std\": \"11.11ms\", \"calls\": 257}, \"rewarder.compute_reward\": {\"mean\": \"5.32ms\", \"std\": \"14.62ms\", \"calls\": 257}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.47081712062256803, \"std\": 0.5591257419675283, \"calls\": 257}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 94}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 96}} gauges={\"reward_parser.score.last_score\": {\"calls\": 113, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=403.17us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:17,843] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.04s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1968 bytes>', 'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:17,900] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=24.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=209333.3 vnc_pixels_ps[total]=111396.5 reward_lag=None rewarder_message_lag=None fps=50.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:18,241] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:19,874] [INFO:root] [Rewarder] Rewarder fell behind by 0.11615896224975586s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:19,919] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=22.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=200253.0 vnc_pixels_ps[total]=110304.1 reward_lag=None rewarder_message_lag=None fps=52.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:20,056] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.34ms\", \"mean\": \"579.50us\", \"calls\": 255}, \"rewarder.frame\": {\"std\": \"11.81ms\", \"mean\": \"20.71ms\", \"calls\": 255}, \"reward.parsing.gameover\": {\"std\": \"725.91us\", \"mean\": \"469.46us\", \"calls\": 100}, \"rewarder.sleep.missed\": {\"std\": \"18.92ms\", \"mean\": \"42.29ms\", \"calls\": 18}, \"reward.parsing.score\": {\"std\": \"22.16ms\", \"mean\": \"10.72ms\", \"calls\": 100}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"1.31ms\", \"mean\": \"425.80us\", \"calls\": 100}, \"score.crop_cache.get.MatchImage\": {\"std\": \"583.56us\", \"mean\": \"236.03us\", \"calls\": 100}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"37.60us\", \"mean\": \"160.60us\", \"calls\": 16}, \"rewarder.sleep\": {\"std\": \"2.64ms\", \"mean\": \"13.97ms\", \"calls\": 237}, \"rewarder.compute_reward\": {\"std\": \"14.95ms\", \"mean\": \"5.41ms\", \"calls\": 255}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"12.52ms\", \"mean\": \"58.53ms\", \"calls\": 16}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5234061434920658, \"mean\": 0.40784313725490207, \"calls\": 255}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 84}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 84}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 100}} (export_time=631.81us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:20,058] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1965 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:20,164] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=21.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=196869.3 vnc_pixels_ps[total]=106900.1 reward_lag=None rewarder_message_lag=None fps=50.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:20,531] [INFO:root] [Rewarder] Rewarder fell behind by 0.11183953285217285s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:20,538] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.compute_reward\": {\"std\": \"14.54ms\", \"calls\": 263, \"mean\": \"4.66ms\"}, \"rewarder.sleep.missed\": {\"std\": \"27.84ms\", \"calls\": 16, \"mean\": \"39.25ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"416.49us\", \"calls\": 100, \"mean\": \"246.89us\"}, \"reward.parsing.gameover\": {\"std\": \"628.05us\", \"calls\": 100, \"mean\": \"547.55us\"}, \"rewarder.frame\": {\"std\": \"11.45ms\", \"calls\": 263, \"mean\": \"20.07ms\"}, \"rewarder.sleep\": {\"std\": \"2.50ms\", \"calls\": 247, \"mean\": \"13.97ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"26.66ms\", \"calls\": 14, \"mean\": \"57.11ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"901.14us\", \"calls\": 263, \"mean\": \"395.03us\"}, \"reward.parsing.score\": {\"std\": \"22.07ms\", \"calls\": 100, \"mean\": \"9.20ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"340.19us\", \"calls\": 100, \"mean\": \"249.99us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"87.91us\", \"calls\": 14, \"mean\": \"191.08us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.5437629724989881, \"calls\": 263, \"mean\": 0.40684410646387836}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 86, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 86, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 100, \"mean\": 2954.0}} (export_time=604.39us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:20,539] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1964 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:21,921] [INFO:root] [Rewarder] Rewarder fell behind by 0.11786746978759766s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:22,794] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep.missed\": {\"std\": \"0.00us\", \"calls\": 1, \"mean\": \"2.47ms\"}, \"rewarder.sleep\": {\"std\": \"1.36ms\", \"calls\": 299, \"mean\": \"15.47ms\"}, \"rewarder.compute_reward\": {\"std\": \"1.10ms\", \"calls\": 300, \"mean\": \"727.93us\"}, \"rewarder.frame\": {\"std\": \"1.14ms\", \"calls\": 300, \"mean\": \"17.07ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"835.96us\", \"calls\": 300, \"mean\": \"334.34us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 300, \"mean\": 0.0}} gauges={} (export_time=291.59us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:22,797] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<852 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:22,812] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"543.53us\", \"std\": \"1.88ms\", \"calls\": 91}, \"rewarder.sleep\": {\"mean\": \"13.49ms\", \"std\": \"3.06ms\", \"calls\": 260}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"360.35us\", \"std\": \"933.53us\", \"calls\": 91}, \"reward.parsing.score\": {\"mean\": \"5.95ms\", \"std\": \"20.56ms\", \"calls\": 91}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"567.51us\", \"std\": \"1.45ms\", \"calls\": 273}, \"reward.parsing.gameover\": {\"mean\": \"1.03ms\", \"std\": \"2.19ms\", \"calls\": 91}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"208.47us\", \"std\": \"91.08us\", \"calls\": 5}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"79.82ms\", \"std\": \"44.38ms\", \"calls\": 5}, \"rewarder.sleep.missed\": {\"mean\": \"34.85ms\", \"std\": \"38.05ms\", \"calls\": 13}, \"rewarder.frame\": {\"mean\": \"19.82ms\", \"std\": \"11.14ms\", \"calls\": 273}, \"rewarder.compute_reward\": {\"mean\": \"3.63ms\", \"std\": \"12.61ms\", \"calls\": 273}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.35164835164835156, \"std\": 0.5224439114342319, \"calls\": 273}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 86}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 86}} gauges={\"reward_parser.score.last_score\": {\"calls\": 91, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=734.09us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:22,817] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.97s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1955 bytes>', 'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:22,906] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=19.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=113048.3 vnc_pixels_ps[total]=78848.1 reward_lag=None rewarder_message_lag=None fps=55.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:23,224] [INFO:root] [Rewarder] Rewarder fell behind by 0.10916590690612793s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:23,246] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=59.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:23,413] [INFO:root] [Rewarder] Rewarder fell behind by 0.17120957374572754s from target; losing 10 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:23,652] [INFO:root] [Rewarder] Rewarder fell behind by 0.1633286476135254s from target; losing 9 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:24,543] [INFO:root] [Rewarder] Rewarder fell behind by 0.10327672958374023s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:24,934] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=17.2 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=108340.2 vnc_pixels_ps[total]=78584.9 reward_lag=None rewarder_message_lag=None fps=51.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:25,046] [INFO:root] [Rewarder] Rewarder fell behind by 0.10811686515808105s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:25,069] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.95ms\", \"mean\": \"722.48us\", \"calls\": 261}, \"rewarder.frame\": {\"std\": \"16.01ms\", \"mean\": \"21.34ms\", \"calls\": 261}, \"reward.parsing.gameover\": {\"std\": \"1.26ms\", \"mean\": \"1.02ms\", \"calls\": 71}, \"rewarder.sleep.missed\": {\"std\": \"48.66ms\", \"mean\": \"34.59ms\", \"calls\": 19}, \"reward.parsing.score\": {\"std\": \"31.83ms\", \"mean\": \"9.78ms\", \"calls\": 71}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"323.24us\", \"mean\": \"297.69us\", \"calls\": 71}, \"score.crop_cache.get.MatchImage\": {\"std\": \"1.13ms\", \"mean\": \"615.42us\", \"calls\": 71}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"10.79us\", \"mean\": \"233.51us\", \"calls\": 5}, \"rewarder.sleep\": {\"std\": \"3.57ms\", \"mean\": \"12.96ms\", \"calls\": 242}, \"rewarder.compute_reward\": {\"std\": \"17.37ms\", \"mean\": \"4.80ms\", \"calls\": 261}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"39.31ms\", \"mean\": \"117.59ms\", \"calls\": 5}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5374015924419021, \"mean\": 0.30268199233716486, \"calls\": 261}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 66}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 66}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 71}} (export_time=725.51us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:25,072] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1954 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:25,184] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=15.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=93415.9 vnc_pixels_ps[total]=73341.1 reward_lag=None rewarder_message_lag=None fps=52.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:25,655] [INFO:universe.pyprofile] [pyprofile] period=5.12s timers={\"rewarder.compute_reward\": {\"std\": \"18.76ms\", \"calls\": 259, \"mean\": \"5.64ms\"}, \"rewarder.sleep.missed\": {\"std\": \"47.19ms\", \"calls\": 21, \"mean\": \"33.56ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"503.90us\", \"calls\": 82, \"mean\": \"326.26us\"}, \"reward.parsing.gameover\": {\"std\": \"2.36ms\", \"calls\": 82, \"mean\": \"1.15ms\"}, \"rewarder.frame\": {\"std\": \"16.21ms\", \"calls\": 259, \"mean\": \"20.73ms\"}, \"rewarder.sleep\": {\"std\": \"3.16ms\", \"calls\": 238, \"mean\": \"13.43ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"10.90ms\", \"calls\": 7, \"mean\": \"104.38ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"2.24ms\", \"calls\": 259, \"mean\": \"856.40us\"}, \"reward.parsing.score\": {\"std\": \"31.14ms\", \"calls\": 82, \"mean\": \"11.22ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"1.96ms\", \"calls\": 82, \"mean\": \"545.46us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"2.32ms\", \"calls\": 8, \"mean\": \"1.21ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.5523939048082073, \"calls\": 259, \"mean\": 0.3474903474903476}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 74, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 75, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 82, \"mean\": 2954.0}} (export_time=473.74us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:25,667] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.13s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 21640, 'rewarder.profile': '<1955 bytes>', 'rewarder.vnc.updates.bytes': 36882, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:25,669] [INFO:root] [Rewarder] Rewarder fell behind by 0.10092377662658691s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:26,241] [INFO:root] [Rewarder] Rewarder fell behind by 0.10100889205932617s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:26,485] [INFO:gym_controlplane.registration] Loaded scorer: <gym_controlplane.reward.score.OCRScorerV0 object at 0x7f3f663d6780>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:26,509] [INFO:root] [Rewarder] Rewarder fell behind by 0.11909627914428711s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:26,995] [INFO:root] [Rewarder] Rewarder fell behind by 0.11351609230041504s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:27,325] [INFO:root] [Rewarder] Rewarder fell behind by 0.11201024055480957s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:27,538] [INFO:root] [Rewarder] Rewarder fell behind by 0.1017909049987793s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:27,795] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.sleep.missed\": {\"std\": \"0.00us\", \"calls\": 1, \"mean\": \"182.87us\"}, \"rewarder.sleep\": {\"std\": \"1.08ms\", \"calls\": 299, \"mean\": \"15.44ms\"}, \"rewarder.compute_reward\": {\"std\": \"678.68us\", \"calls\": 300, \"mean\": \"700.26us\"}, \"rewarder.frame\": {\"std\": \"984.01us\", \"calls\": 300, \"mean\": \"17.09ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"573.85us\", \"calls\": 300, \"mean\": \"290.02us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 300, \"mean\": 0.0}} gauges={} (export_time=329.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:27,795] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<855 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:27,831] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"290.77us\", \"std\": \"356.26us\", \"calls\": 79}, \"rewarder.sleep\": {\"mean\": \"13.59ms\", \"std\": \"3.14ms\", \"calls\": 233}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"649.89us\", \"std\": \"2.05ms\", \"calls\": 79}, \"reward.parsing.score\": {\"mean\": \"11.16ms\", \"std\": \"29.42ms\", \"calls\": 79}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"774.25us\", \"std\": \"1.73ms\", \"calls\": 251}, \"reward.parsing.gameover\": {\"mean\": \"1.79ms\", \"std\": \"4.65ms\", \"calls\": 79}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"524.97us\", \"std\": \"475.03us\", \"calls\": 8}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"96.34ms\", \"std\": \"14.18ms\", \"calls\": 8}, \"rewarder.sleep.missed\": {\"mean\": \"45.08ms\", \"std\": \"42.07ms\", \"calls\": 18}, \"rewarder.frame\": {\"mean\": \"21.43ms\", \"std\": \"16.29ms\", \"calls\": 251}, \"rewarder.compute_reward\": {\"mean\": \"5.49ms\", \"std\": \"17.90ms\", \"calls\": 251}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.33864541832669326, \"std\": 0.537457493918286, \"calls\": 251}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 71}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 71}} gauges={\"reward_parser.score.last_score\": {\"calls\": 79, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=8.69ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:27,834] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 1840, 'rewarder.profile': '<1959 bytes>', 'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 5540}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:27,912] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=16.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=117168.3 vnc_pixels_ps[total]=81821.8 reward_lag=None rewarder_message_lag=None fps=49.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:28,000] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:28,003] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:28,262] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:28,544] [INFO:root] [Rewarder] Rewarder fell behind by 0.10922479629516602s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:29,006] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:29,011] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:29,015] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:29,100] [INFO:root] [Rewarder] Rewarder fell behind by 0.11546587944030762s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:29,228] [INFO:root] [Rewarder] Rewarder fell behind by 0.10912370681762695s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:29,793] [INFO:root] [Rewarder] Rewarder fell behind by 0.1108708381652832s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:29,953] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=18.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=135474.4 vnc_pixels_ps[total]=87007.7 reward_lag=None rewarder_message_lag=None fps=48.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:30,018] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:30,013] [INFO:gym_controlplane.registration] Created reward parser for flashgames.DuskDrive-v0: Reward<scorer=<gym_controlplane.reward.score.OCRScorerV0 object at 0x7f3f663d6780> vexpect=VExpect<{'initializing0': <gym_controlplane.integration.transition.ClickTransition object at 0x7f3f39db51d0>, 'ready3': <gym_controlplane.integration.transition.ClickTransition object at 0x7f3f384fa0f0>, 'initializing2': <gym_controlplane.integration.transition.ClickTransition object at 0x7f3f39db94e0>, 'ready1': <gym_controlplane.integration.transition.ClickTransition object at 0x7f3f384f9550>, 'ready0': <gym_controlplane.integration.transition.ClickTransition object at 0x7f3f39db9f60>, 'initializing1': <gym_controlplane.integration.transition.ClickTransition object at 0x7f3f39db5b38>, 'ready2': <gym_controlplane.integration.transition.ClickTransition object at 0x7f3f384f9b00>}>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:30,021] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:30,013] [INFO:root] Using metadata_encoding={'height': 100, 'width': 100, 'y': 658, 'type': 'qrcode', 'x': 914} probe_key=96 subscription=[(548, 100, 442, 100), (82, 92, 128, 20), (914, 100, 658, 100)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:30,028] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:30,014] [INFO:universe.rewarder.remote] [Rewarder] Over past 81.85s, sent 0 reward messages to agent: reward=0 reward_min=(empty) reward_max=(empty) done=False info={}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:30,015] [INFO:universe.rewarder.remote] [Rewarder] Ending previous episode: episode_reward=0 episode_count=1 episode_duration=86.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m 2017/01/15 16:00:30 I0115 16:00:30.028835 57 gymvnc.go:278] [0:127.0.0.1:5900] resuming updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:30,041] [INFO:universe.wrappers.logger] Stats for the past 81.85s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=3.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:30,078] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"2.50ms\", \"mean\": \"1.07ms\", \"calls\": 205}, \"rewarder.frame\": {\"std\": \"24.28ms\", \"mean\": \"25.68ms\", \"calls\": 205}, \"reward.parsing.gameover\": {\"std\": \"1.69ms\", \"mean\": \"999.39us\", \"calls\": 78}, \"rewarder.sleep.missed\": {\"std\": \"38.17ms\", \"mean\": \"61.22ms\", \"calls\": 26}, \"reward.parsing.score\": {\"std\": \"40.73ms\", \"mean\": \"23.29ms\", \"calls\": 78}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"192.46us\", \"mean\": \"235.50us\", \"calls\": 78}, \"score.crop_cache.get.MatchImage\": {\"std\": \"1.11ms\", \"mean\": \"541.86us\", \"calls\": 78}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"427.78us\", \"mean\": \"353.55us\", \"calls\": 21}, \"rewarder.sleep\": {\"std\": \"2.78ms\", \"mean\": \"13.55ms\", \"calls\": 179}, \"rewarder.compute_reward\": {\"std\": \"28.18ms\", \"mean\": \"11.09ms\", \"calls\": 205}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"22.92ms\", \"mean\": \"90.78ms\", \"calls\": 19}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.6439951819359885, \"mean\": 0.4439024390243903, \"calls\": 205}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 57}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 59}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 78}} (export_time=478.74us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:30,079] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1955 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:30,284] [INFO:universe.wrappers.logger] Stats for the past 5.08s: vnc_updates_ps=18.5 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=195236.3 vnc_pixels_ps[total]=106355.0 reward_lag=None rewarder_message_lag=None fps=39.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:30,483] [INFO:universe.pyprofile] [pyprofile] period=82.32s timers={\"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"mean\": \"5.64ms\", \"std\": \"2.93ms\", \"calls\": 11}, \"rewarder.frame\": {\"mean\": \"17.09ms\", \"std\": \"1.21ms\", \"calls\": 278}, \"rewarder.sleep\": {\"mean\": \"15.54ms\", \"std\": \"1.41ms\", \"calls\": 278}, \"reward.parsing.score\": {\"mean\": \"439.05ms\", \"std\": \"0.00us\", \"calls\": 1}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"10.73us\", \"std\": \"0.00us\", \"calls\": 1}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"195.50us\", \"std\": \"0.00us\", \"calls\": 1}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"438.78ms\", \"std\": \"0.00us\", \"calls\": 1}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"29.33us\", \"std\": \"0.00us\", \"calls\": 1}, \"reward.parsing.gameover\": {\"mean\": \"382.66us\", \"std\": \"0.00us\", \"calls\": 1}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"269.96us\", \"std\": \"485.50us\", \"calls\": 278}, \"rewarder.compute_reward\": {\"mean\": \"2.25ms\", \"std\": \"28.01ms\", \"calls\": 278}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"control.env_id_change\": {\"mean\": 1.0, \"std\": 0, \"calls\": 1}, \"control.env_id_change.flashgames.DuskDrive-v0\": {\"mean\": 1.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.21942446043165467, \"std\": 3.6585368778148095, \"calls\": 278}, \"rewarder_protocol.messages\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 11}, \"rewarder_protocol.messages.v0.control.ping\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 10}, \"rewarder_protocol.messages.v0.env.reset\": {\"mean\": 1.0, \"std\": 0, \"calls\": 1}} gauges={} (export_time=339.51us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:30,485] [INFO:root] [Rewarder] Rewarder fell behind by 38.556830406188965s from target; losing 2313 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:30,554] [INFO:gym_controlplane.reward.reward] First score parsed: score=2954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:30,686] [INFO:universe.pyprofile] [pyprofile] period=5.03s timers={\"rewarder.compute_reward\": {\"std\": \"20.25ms\", \"calls\": 245, \"mean\": \"6.63ms\"}, \"rewarder.sleep.missed\": {\"std\": \"44.44ms\", \"calls\": 21, \"mean\": \"46.46ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"324.72us\", \"calls\": 87, \"mean\": \"274.61us\"}, \"reward.parsing.gameover\": {\"std\": \"1.45ms\", \"calls\": 87, \"mean\": \"914.05us\"}, \"rewarder.frame\": {\"std\": \"18.26ms\", \"calls\": 245, \"mean\": \"22.03ms\"}, \"rewarder.sleep\": {\"std\": \"2.92ms\", \"calls\": 224, \"mean\": \"13.40ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"26.14ms\", \"calls\": 11, \"mean\": \"91.38ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"2.57ms\", \"calls\": 245, \"mean\": \"913.72us\"}, \"reward.parsing.score\": {\"std\": \"31.89ms\", \"calls\": 87, \"mean\": \"12.96ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"902.53us\", \"calls\": 87, \"mean\": \"354.94us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"79.95us\", \"calls\": 13, \"mean\": \"216.23us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.5675512483805378, \"calls\": 245, \"mean\": 0.3959183673469386}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 74, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 76, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 87, \"mean\": 2954.0}} (export_time=442.03us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:30,687] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<1959 bytes>', 'rewarder.vnc.updates.bytes': 35562, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:31,034] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:31,037] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:31,040] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:32,042] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:32,044] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:32,047] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:32,810] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"415.32us\", \"calls\": 301, \"mean\": \"244.83us\"}, \"rewarder.sleep\": {\"std\": \"1.22ms\", \"calls\": 301, \"mean\": \"15.65ms\"}, \"rewarder.compute_reward\": {\"std\": \"482.71us\", \"calls\": 301, \"mean\": \"551.47us\"}, \"rewarder.frame\": {\"std\": \"1.12ms\", \"calls\": 301, \"mean\": \"17.00ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 301, \"mean\": 0.0}} gauges={} (export_time=248.19us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:32,811] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<752 bytes>'}\n\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:32,841] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"205.89us\", \"std\": \"244.85us\", \"calls\": 92}, \"rewarder.sleep\": {\"mean\": \"13.77ms\", \"std\": \"2.95ms\", \"calls\": 209}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"588.39us\", \"std\": \"1.95ms\", \"calls\": 92}, \"reward.parsing.score\": {\"mean\": \"15.60ms\", \"std\": \"30.73ms\", \"calls\": 92}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"446.97us\", \"std\": \"1.18ms\", \"calls\": 231}, \"reward.parsing.gameover\": {\"mean\": \"1.11ms\", \"std\": \"2.34ms\", \"calls\": 92}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"215.09us\", \"std\": \"91.83us\", \"calls\": 21}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"71.22ms\", \"std\": \"21.52ms\", \"calls\": 19}, \"rewarder.sleep.missed\": {\"mean\": \"53.67ms\", \"std\": \"28.03ms\", \"calls\": 22}, \"rewarder.frame\": {\"mean\": \"23.02ms\", \"std\": \"17.67ms\", \"calls\": 231}, \"rewarder.compute_reward\": {\"mean\": \"7.74ms\", \"std\": \"21.33ms\", \"calls\": 231}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.4372294372294372, \"std\": 0.578001906269712, \"calls\": 231}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 71}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 73}} gauges={\"reward_parser.score.last_score\": {\"calls\": 92, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=380.75us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:32,842] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 1840, 'rewarder.profile': '<1958 bytes>', 'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 5540}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:32,930] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=20.3 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=202580.9 vnc_pixels_ps[total]=109606.6 reward_lag=None rewarder_message_lag=None fps=46.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:33,050] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:33,053] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:33,058] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:33,278] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:33,627] [INFO:root] [Rewarder] Rewarder fell behind by 0.13638544082641602s from target; losing 8 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:34,063] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:34,066] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:34,072] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:34,346] [INFO:root] [Rewarder] Rewarder fell behind by 0.10121369361877441s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:34,944] [INFO:root] [Rewarder] Rewarder fell behind by 0.12813639640808105s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:34,971] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=23.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=223180.1 vnc_pixels_ps[total]=116759.7 reward_lag=None rewarder_message_lag=None fps=46.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:35,078] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:35,081] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:35,085] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:35,088] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"2.04ms\", \"mean\": \"640.19us\", \"calls\": 262}, \"rewarder.frame\": {\"std\": \"10.33ms\", \"mean\": \"19.66ms\", \"calls\": 262}, \"reward.parsing.gameover\": {\"std\": \"815.60us\", \"mean\": \"580.35us\", \"calls\": 99}, \"rewarder.sleep.missed\": {\"std\": \"23.48ms\", \"mean\": \"41.35ms\", \"calls\": 13}, \"reward.parsing.score\": {\"std\": \"22.14ms\", \"mean\": \"8.56ms\", \"calls\": 99}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"832.47us\", \"mean\": \"318.27us\", \"calls\": 99}, \"score.crop_cache.get.MatchImage\": {\"std\": \"467.70us\", \"mean\": \"277.54us\", \"calls\": 99}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"61.08us\", \"mean\": \"157.28us\", \"calls\": 10}, \"rewarder.sleep\": {\"std\": \"2.56ms\", \"mean\": \"14.22ms\", \"calls\": 249}, \"rewarder.compute_reward\": {\"std\": \"14.45ms\", \"mean\": \"4.49ms\", \"calls\": 262}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"17.91ms\", \"mean\": \"67.80ms\", \"calls\": 11}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.6005174569565003, \"mean\": 0.4274809160305342, \"calls\": 262}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 89}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 88}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 99}} (export_time=2.11ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:35,098] [INFO:universe.wrappers.logger] Stats for the past 5.05s: vnc_updates_ps=34.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=693252.6 vnc_pixels_ps[total]=826604.6 reward_lag=None rewarder_message_lag=None fps=47.49\n\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:35,105] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.03s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.n': 1, 'rewarder.profile': '<1958 bytes>', 'rewarder.vnc.updates.pixels': 1840, 'rewarder.vnc.updates.bytes': 5540}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:35,109] [INFO:root] [Rewarder] Rewarder fell behind by 0.11123871803283691s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:35,341] [INFO:universe.wrappers.logger] Stats for the past 5.05s: vnc_updates_ps=22.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=155097.9 vnc_pixels_ps[total]=95615.5 reward_lag=None rewarder_message_lag=None fps=53.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:35,498] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"mean\": \"165.96ms\", \"std\": \"2.37s\", \"calls\": 264}, \"rewarder.sleep\": {\"mean\": \"14.18ms\", \"std\": \"2.31ms\", \"calls\": 249}, \"reward.parsing.score\": {\"mean\": \"8.06ms\", \"std\": \"21.88ms\", \"calls\": 102}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"403.52us\", \"std\": \"1.34ms\", \"calls\": 102}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"226.74us\", \"std\": \"245.59us\", \"calls\": 11}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"65.91ms\", \"std\": \"21.17ms\", \"calls\": 11}, \"rewarder.sleep.missed\": {\"mean\": \"2.61s\", \"std\": \"9.94s\", \"calls\": 15}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"252.31us\", \"std\": \"725.00us\", \"calls\": 102}, \"reward.parsing.gameover\": {\"mean\": \"742.30us\", \"std\": \"1.47ms\", \"calls\": 102}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"574.63us\", \"std\": \"1.42ms\", \"calls\": 264}, \"rewarder.compute_reward\": {\"mean\": \"4.55ms\", \"std\": \"14.60ms\", \"calls\": 264}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.45454545454545503, \"std\": 0.8966658678317099, \"calls\": 264}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 91}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 91}} gauges={\"reward_parser.score.last_score\": {\"value\": 2954.0, \"mean\": 2954.0, \"std\": 0.0, \"calls\": 101}} (export_time=953.67us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:35,504] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.49s, sent 2 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1957 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:35,688] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.compute_reward\": {\"std\": \"21.55ms\", \"calls\": 233, \"mean\": \"7.21ms\"}, \"rewarder.sleep.missed\": {\"std\": \"29.34ms\", \"calls\": 20, \"mean\": \"59.27ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"800.20us\", \"calls\": 101, \"mean\": \"310.99us\"}, \"reward.parsing.gameover\": {\"std\": \"1.01ms\", \"calls\": 101, \"mean\": \"646.64us\"}, \"rewarder.frame\": {\"std\": \"18.47ms\", \"calls\": 233, \"mean\": \"22.78ms\"}, \"rewarder.sleep\": {\"std\": \"2.19ms\", \"calls\": 213, \"mean\": \"14.31ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"29.21ms\", \"calls\": 19, \"mean\": \"70.99ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"656.26us\", \"calls\": 233, \"mean\": \"317.72us\"}, \"reward.parsing.score\": {\"std\": \"30.64ms\", \"calls\": 101, \"mean\": \"14.25ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"410.83us\", \"calls\": 101, \"mean\": \"247.98us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"562.12us\", \"calls\": 19, \"mean\": \"305.14us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.6023055206538891, \"calls\": 233, \"mean\": 0.48068669527897007}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 82, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 82, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 101, \"mean\": 2954.0}} (export_time=298.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:35,690] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1964 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:35,783] [INFO:root] [Rewarder] Rewarder fell behind by 0.10354375839233398s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:35,836] [INFO:root] [Rewarder] Rewarder fell behind by 0.10013246536254883s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:36,089] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:36,092] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:36,097] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:36,151] [INFO:root] [Rewarder] Rewarder fell behind by 0.11711788177490234s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m Setting VNC and rewarder password: openai\n\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:37,223] [INFO:root] [Rewarder] Rewarder fell behind by 0.11609148979187012s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:37,293] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:37,301] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:37,304] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:37,317] [INFO:root] [Rewarder] Rewarder fell behind by 0.11632037162780762s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:37,489] [INFO:root] [Rewarder] Rewarder fell behind by 0.10086560249328613s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:37,686] [INFO:root] [Rewarder] Rewarder fell behind by 0.12458133697509766s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:37,702] [INFO:root] [Rewarder] Rewarder fell behind by 0.11054444313049316s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:37,810] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"302.75us\", \"calls\": 300, \"mean\": \"223.04us\"}, \"rewarder.sleep\": {\"std\": \"876.38us\", \"calls\": 300, \"mean\": \"15.71ms\"}, \"rewarder.compute_reward\": {\"std\": \"685.85us\", \"calls\": 300, \"mean\": \"597.82us\"}, \"rewarder.frame\": {\"std\": \"529.69us\", \"calls\": 300, \"mean\": \"16.89ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 300, \"mean\": 0.0}} gauges={} (export_time=244.14us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:37,811] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<744 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:37,880] [INFO:universe.pyprofile] [pyprofile] period=5.04s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"377.79us\", \"std\": \"1.42ms\", \"calls\": 79}, \"rewarder.sleep\": {\"mean\": \"13.39ms\", \"std\": \"3.39ms\", \"calls\": 202}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"510.27us\", \"std\": \"1.37ms\", \"calls\": 79}, \"reward.parsing.score\": {\"mean\": \"19.71ms\", \"std\": \"36.65ms\", \"calls\": 79}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"887.57us\", \"std\": \"2.47ms\", \"calls\": 225}, \"reward.parsing.gameover\": {\"mean\": \"895.62us\", \"std\": \"1.66ms\", \"calls\": 79}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"629.07us\", \"std\": \"1.73ms\", \"calls\": 17}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"85.54ms\", \"std\": \"22.67ms\", \"calls\": 17}, \"rewarder.sleep.missed\": {\"mean\": \"52.08ms\", \"std\": \"37.59ms\", \"calls\": 23}, \"rewarder.frame\": {\"mean\": \"23.34ms\", \"std\": \"19.53ms\", \"calls\": 225}, \"rewarder.compute_reward\": {\"mean\": \"8.80ms\", \"std\": \"24.01ms\", \"calls\": 225}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.4266666666666668, \"std\": 0.6444820733404016, \"calls\": 225}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 62}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 62}} gauges={\"reward_parser.score.last_score\": {\"calls\": 79, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=492.33us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:37,897] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.05s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 11840, 'rewarder.profile': '<1953 bytes>', 'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 35562}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:37,906] [INFO:root] [Rewarder] Rewarder fell behind by 0.11277890205383301s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:37,933] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=19.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=181280.4 vnc_pixels_ps[total]=103537.9 reward_lag=None rewarder_message_lag=None fps=44.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:38,015] [INFO:root] [Rewarder] Rewarder fell behind by 0.10753774642944336s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:38,294] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:38,308] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:38,311] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:38,314] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:39,317] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:39,319] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:39,321] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:39,980] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=20.8 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=201721.5 vnc_pixels_ps[total]=109000.0 reward_lag=None rewarder_message_lag=None fps=43.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:40,103] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.34ms\", \"mean\": \"497.62us\", \"calls\": 242}, \"rewarder.frame\": {\"std\": \"17.57ms\", \"mean\": \"22.41ms\", \"calls\": 242}, \"reward.parsing.gameover\": {\"std\": \"1.96ms\", \"mean\": \"927.86us\", \"calls\": 88}, \"rewarder.sleep.missed\": {\"std\": \"33.88ms\", \"mean\": \"54.09ms\", \"calls\": 20}, \"reward.parsing.score\": {\"std\": \"29.30ms\", \"mean\": \"14.06ms\", \"calls\": 88}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"626.33us\", \"mean\": \"294.65us\", \"calls\": 88}, \"score.crop_cache.get.MatchImage\": {\"std\": \"397.39us\", \"mean\": \"250.14us\", \"calls\": 88}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"2.17ms\", \"mean\": \"933.17us\", \"calls\": 17}, \"rewarder.sleep\": {\"std\": \"2.74ms\", \"mean\": \"13.76ms\", \"calls\": 222}, \"rewarder.compute_reward\": {\"std\": \"19.53ms\", \"mean\": \"6.59ms\", \"calls\": 242}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"23.90ms\", \"mean\": \"70.88ms\", \"calls\": 16}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5844245656833549, \"mean\": 0.4049586776859506, \"calls\": 242}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 71}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 72}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 88}} (export_time=475.17us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:40,105] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1960 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:40,124] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=19.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=197939.7 vnc_pixels_ps[total]=108730.6 reward_lag=None rewarder_message_lag=None fps=45.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:40,324] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:40,327] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:40,330] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:40,360] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=19.7 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=188136.1 vnc_pixels_ps[total]=103536.7 reward_lag=None rewarder_message_lag=None fps=48.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:40,572] [INFO:universe.pyprofile] [pyprofile] period=5.08s timers={\"rewarder.frame\": {\"mean\": \"23.28ms\", \"std\": \"17.96ms\", \"calls\": 225}, \"rewarder.sleep\": {\"mean\": \"13.93ms\", \"std\": \"2.78ms\", \"calls\": 199}, \"reward.parsing.score\": {\"mean\": \"18.72ms\", \"std\": \"32.59ms\", \"calls\": 84}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"593.57us\", \"std\": \"2.83ms\", \"calls\": 84}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"284.28us\", \"std\": \"348.69us\", \"calls\": 22}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"70.09ms\", \"std\": \"21.25ms\", \"calls\": 21}, \"rewarder.sleep.missed\": {\"mean\": \"47.99ms\", \"std\": \"28.67ms\", \"calls\": 26}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"227.85us\", \"std\": \"287.09us\", \"calls\": 84}, \"reward.parsing.gameover\": {\"mean\": \"1.13ms\", \"std\": \"3.31ms\", \"calls\": 84}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"852.89us\", \"std\": \"2.32ms\", \"calls\": 225}, \"rewarder.compute_reward\": {\"mean\": \"8.92ms\", \"std\": \"22.36ms\", \"calls\": 225}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.44888888888888895, \"std\": 0.6602969509940685, \"calls\": 225}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 62}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 63}} gauges={\"reward_parser.score.last_score\": {\"value\": 2954.0, \"mean\": 2954.0, \"std\": 0.0, \"calls\": 84}} (export_time=361.92us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:40,573] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.07s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 11840, 'rewarder.vnc.updates.bytes': 35580, 'rewarder.vnc.updates.n': 2, 'rewarder.profile': '<1959 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:40,702] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.compute_reward\": {\"std\": \"24.79ms\", \"calls\": 222, \"mean\": \"8.51ms\"}, \"rewarder.sleep.missed\": {\"std\": \"27.07ms\", \"calls\": 18, \"mean\": \"72.36ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"485.12us\", \"calls\": 93, \"mean\": \"258.17us\"}, \"reward.parsing.gameover\": {\"std\": \"1.47ms\", \"calls\": 93, \"mean\": \"802.88us\"}, \"rewarder.frame\": {\"std\": \"21.26ms\", \"calls\": 222, \"mean\": \"23.33ms\"}, \"rewarder.sleep\": {\"std\": \"2.46ms\", \"calls\": 204, \"mean\": \"14.21ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"24.51ms\", \"calls\": 18, \"mean\": \"81.59ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.65ms\", \"calls\": 222, \"mean\": \"520.41us\"}, \"reward.parsing.score\": {\"std\": \"34.08ms\", \"calls\": 93, \"mean\": \"16.95ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"1.14ms\", \"calls\": 93, \"mean\": \"416.84us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"47.69us\", \"calls\": 19, \"mean\": \"196.33us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.6433860581548008, \"calls\": 222, \"mean\": 0.49099099099099053}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 74, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 75, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 93, \"mean\": 2954.0}} (export_time=494.48us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:40,718] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.03s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1961 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:41,332] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:41,350] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:41,354] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:41,709] [INFO:root] [Rewarder] Rewarder fell behind by 0.11334371566772461s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:42,226] [INFO:root] [Rewarder] Rewarder fell behind by 0.11783528327941895s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:42,359] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:42,362] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:42,366] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:42,810] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"614.66us\", \"calls\": 300, \"mean\": \"271.60us\"}, \"rewarder.sleep\": {\"std\": \"994.84us\", \"calls\": 300, \"mean\": \"15.71ms\"}, \"rewarder.compute_reward\": {\"std\": \"689.13us\", \"calls\": 300, \"mean\": \"561.39us\"}, \"rewarder.frame\": {\"std\": \"677.51us\", \"calls\": 300, \"mean\": \"16.94ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 300, \"mean\": 0.0}} gauges={} (export_time=240.09us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:42,811] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<755 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:42,890] [INFO:root] [Rewarder] Rewarder fell behind by 0.1055605411529541s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:42,886] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"291.35us\", \"std\": \"1.00ms\", \"calls\": 100}, \"rewarder.sleep\": {\"mean\": \"14.27ms\", \"std\": \"2.62ms\", \"calls\": 218}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"422.43us\", \"std\": \"1.28ms\", \"calls\": 100}, \"reward.parsing.score\": {\"mean\": \"11.85ms\", \"std\": \"26.22ms\", \"calls\": 100}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"735.18us\", \"std\": \"2.38ms\", \"calls\": 241}, \"reward.parsing.gameover\": {\"mean\": \"840.98us\", \"std\": \"2.07ms\", \"calls\": 100}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"200.84us\", \"std\": \"73.84us\", \"calls\": 18}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"64.41ms\", \"std\": \"23.44ms\", \"calls\": 17}, \"rewarder.sleep.missed\": {\"mean\": \"46.83ms\", \"std\": \"34.01ms\", \"calls\": 23}, \"rewarder.frame\": {\"mean\": \"22.16ms\", \"std\": \"17.31ms\", \"calls\": 241}, \"rewarder.compute_reward\": {\"mean\": \"6.60ms\", \"std\": \"18.97ms\", \"calls\": 241}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.4605809128630705, \"std\": 0.5911694577706379, \"calls\": 241}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 82}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 83}} gauges={\"reward_parser.score.last_score\": {\"calls\": 100, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=1.36ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:42,893] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1959 bytes>', 'rewarder.vnc.updates.n': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:42,943] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=22.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=198589.9 vnc_pixels_ps[total]=108267.7 reward_lag=None rewarder_message_lag=None fps=48.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:43,113] [INFO:root] [Rewarder] Rewarder fell behind by 0.1060326099395752s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:43,214] [INFO:root] [Rewarder] Rewarder fell behind by 0.14099502563476562s from target; losing 8 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:43,312] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:43,369] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:43,373] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:43,385] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:43,589] [INFO:root] [Rewarder] Rewarder fell behind by 0.1671750545501709s from target; losing 10 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:43,605] [INFO:root] [Rewarder] Rewarder fell behind by 0.16403794288635254s from target; losing 9 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:43,712] [INFO:root] [Rewarder] Rewarder fell behind by 0.18073534965515137s from target; losing 10 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:43,999] [INFO:root] [Rewarder] Rewarder fell behind by 0.10319304466247559s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *45 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *46 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *47 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *48 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *49 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *50 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *51 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *52 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *53 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [nginx] 2017/01/15 16:00:44 [info] 65#65: *54 client closed connection while waiting for request, client: 172.17.0.1, server: 0.0.0.0:15900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:44,357] [INFO:root] [Rewarder] Rewarder fell behind by 0.17006635665893555s from target; losing 10 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:44,389] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:44,396] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:44,399] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:44,546] [INFO:root] [Rewarder] Rewarder fell behind by 0.22971796989440918s from target; losing 13 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:44,990] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=19.6 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=177059.4 vnc_pixels_ps[total]=100670.3 reward_lag=None rewarder_message_lag=None fps=42.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:45,114] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.frame\": {\"std\": \"17.53ms\", \"mean\": \"21.69ms\", \"calls\": 245}, \"reward.parsing.gameover\": {\"std\": \"1.30ms\", \"mean\": \"774.14us\", \"calls\": 87}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"440.44us\", \"mean\": \"248.53us\", \"calls\": 87}, \"rewarder.sleep\": {\"std\": \"2.73ms\", \"mean\": \"13.91ms\", \"calls\": 229}, \"rewarder.compute_reward\": {\"std\": \"20.15ms\", \"mean\": \"6.04ms\", \"calls\": 245}, \"reward.parsing.score\": {\"std\": \"31.37ms\", \"mean\": \"12.94ms\", \"calls\": 87}, \"rewarder.sleep.missed\": {\"std\": \"41.18ms\", \"mean\": \"57.84ms\", \"calls\": 16}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"32.43ms\", \"mean\": \"79.10ms\", \"calls\": 13}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"2.10ms\", \"mean\": \"1.40ms\", \"calls\": 14}, \"score.crop_cache.get.MatchImage\": {\"std\": \"740.29us\", \"mean\": \"325.67us\", \"calls\": 87}, \"rewarder_protocol.latency.rtt.skew_unadjusted\": {\"std\": \"7.50ms\", \"mean\": \"9.73ms\", \"calls\": 10}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.79ms\", \"mean\": \"522.45us\", \"calls\": 245}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5971102486530471, \"mean\": 0.4040816326530611, \"calls\": 245}, \"rewarder_protocol.messages\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 10}, \"rewarder_protocol.messages.v0.control.ping\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 10}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 73}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 74}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 87}} (export_time=578.17us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:45,115] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<2283 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:45,141] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=17.9 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=165735.2 vnc_pixels_ps[total]=99883.5 reward_lag=None rewarder_message_lag=None fps=47.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:45,366] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=19.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=153097.6 vnc_pixels_ps[total]=92027.6 reward_lag=None rewarder_message_lag=None fps=49.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:45,402] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:45,405] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:45,408] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:45,459] [INFO:root] [Rewarder] Rewarder fell behind by 0.1412944793701172s from target; losing 8 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:45,575] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.frame\": {\"mean\": \"21.95ms\", \"std\": \"16.62ms\", \"calls\": 245}, \"rewarder.sleep\": {\"mean\": \"13.89ms\", \"std\": \"2.75ms\", \"calls\": 229}, \"reward.parsing.score\": {\"mean\": \"14.01ms\", \"std\": \"31.09ms\", \"calls\": 82}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"306.60us\", \"std\": \"650.98us\", \"calls\": 82}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"487.42us\", \"std\": \"679.55us\", \"calls\": 13}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"82.38ms\", \"std\": \"18.98ms\", \"calls\": 13}, \"rewarder.sleep.missed\": {\"mean\": \"61.91ms\", \"std\": \"26.91ms\", \"calls\": 16}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"206.27us\", \"std\": \"214.09us\", \"calls\": 82}, \"reward.parsing.gameover\": {\"mean\": \"719.45us\", \"std\": \"1.02ms\", \"calls\": 82}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"523.70us\", \"std\": \"1.21ms\", \"calls\": 245}, \"rewarder.compute_reward\": {\"mean\": \"5.97ms\", \"std\": \"19.27ms\", \"calls\": 245}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.3591836734693877, \"std\": 0.5294283831143792, \"calls\": 245}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 69}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 69}} gauges={\"reward_parser.score.last_score\": {\"value\": 2954.0, \"mean\": 2954.0, \"std\": 0.0, \"calls\": 82}} (export_time=883.58us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:45,577] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1952 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:45,703] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.compute_reward\": {\"std\": \"28.14ms\", \"calls\": 207, \"mean\": \"10.40ms\"}, \"rewarder.sleep.missed\": {\"std\": \"46.59ms\", \"calls\": 23, \"mean\": \"67.06ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"583.31us\", \"calls\": 77, \"mean\": \"292.06us\"}, \"reward.parsing.gameover\": {\"std\": \"4.03ms\", \"calls\": 77, \"mean\": \"1.62ms\"}, \"rewarder.frame\": {\"std\": \"25.88ms\", \"calls\": 207, \"mean\": \"25.66ms\"}, \"rewarder.sleep\": {\"std\": \"3.02ms\", \"calls\": 184, \"mean\": \"13.48ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"36.37ms\", \"calls\": 17, \"mean\": \"88.17ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"2.95ms\", \"calls\": 207, \"mean\": \"949.84us\"}, \"reward.parsing.score\": {\"std\": \"41.17ms\", \"calls\": 77, \"mean\": \"21.59ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"2.27ms\", \"calls\": 77, \"mean\": \"551.36us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"48.28us\", \"calls\": 17, \"mean\": \"202.91us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.6730383565788708, \"calls\": 207, \"mean\": 0.4541062801932369}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 60, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 60, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 77, \"mean\": 2954.0}} (export_time=514.75us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:45,707] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.99s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.profile': '<1959 bytes>', 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:45,892] [INFO:root] [Rewarder] Rewarder fell behind by 0.10691499710083008s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:46,414] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:46,416] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:46,422] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:47,425] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:47,957] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:47,960] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:47,829] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"945.48us\", \"calls\": 301, \"mean\": \"399.68us\"}, \"rewarder.sleep\": {\"std\": \"1.51ms\", \"calls\": 301, \"mean\": \"15.43ms\"}, \"rewarder.compute_reward\": {\"std\": \"982.70us\", \"calls\": 301, \"mean\": \"707.19us\"}, \"rewarder.frame\": {\"std\": \"1.08ms\", \"calls\": 301, \"mean\": \"17.08ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 301, \"mean\": 0.0}} gauges={} (export_time=209.57us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:47,829] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<757 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:47,887] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"281.61us\", \"std\": \"587.58us\", \"calls\": 86}, \"rewarder.sleep\": {\"mean\": \"13.63ms\", \"std\": \"2.89ms\", \"calls\": 227}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"267.67us\", \"std\": \"501.72us\", \"calls\": 86}, \"reward.parsing.score\": {\"mean\": \"13.05ms\", \"std\": \"41.09ms\", \"calls\": 86}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"556.36us\", \"std\": \"1.55ms\", \"calls\": 240}, \"reward.parsing.gameover\": {\"mean\": \"682.53us\", \"std\": \"1.11ms\", \"calls\": 86}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"566.10us\", \"std\": \"819.94us\", \"calls\": 8}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"127.67ms\", \"std\": \"60.70ms\", \"calls\": 8}, \"rewarder.sleep.missed\": {\"mean\": \"76.60ms\", \"std\": \"71.90ms\", \"calls\": 13}, \"rewarder.frame\": {\"mean\": \"22.21ms\", \"std\": \"23.73ms\", \"calls\": 240}, \"rewarder.compute_reward\": {\"mean\": \"6.26ms\", \"std\": \"25.77ms\", \"calls\": 240}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.3833333333333334, \"std\": 0.5440178026457746, \"calls\": 240}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 78}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 78}} gauges={\"reward_parser.score.last_score\": {\"calls\": 86, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=327.11us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:47,888] [INFO:universe.rewarder.remote] [Rewarder] Over past 4.99s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 1840, 'rewarder.profile': '<1955 bytes>', 'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 5540}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:47,953] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=18.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=126736.7 vnc_pixels_ps[total]=84966.6 reward_lag=None rewarder_message_lag=None fps=48.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:47,589] [INFO:root] [Rewarder] Rewarder fell behind by 0.11452627182006836s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:48,328] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:48,962] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:48,964] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:48,967] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [Sun Jan 15 16:00:49 UTC 2017] Waiting for /tmp/.X11-unix/X0 to be created (try 1/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:49,971] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:49,975] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:49,978] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:49,998] [INFO:universe.wrappers.logger] Stats for the past 5.00s: vnc_updates_ps=21.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=178430.9 vnc_pixels_ps[total]=100944.8 reward_lag=None rewarder_message_lag=None fps=51.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:50,119] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.47ms\", \"mean\": \"502.32us\", \"calls\": 230}, \"rewarder.frame\": {\"std\": \"16.83ms\", \"mean\": \"23.07ms\", \"calls\": 230}, \"reward.parsing.gameover\": {\"std\": \"975.19us\", \"mean\": \"606.01us\", \"calls\": 90}, \"rewarder.sleep.missed\": {\"std\": \"21.01ms\", \"mean\": \"53.07ms\", \"calls\": 22}, \"reward.parsing.score\": {\"std\": \"29.35ms\", \"mean\": \"16.10ms\", \"calls\": 90}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"1.46ms\", \"mean\": \"417.92us\", \"calls\": 90}, \"score.crop_cache.get.MatchImage\": {\"std\": \"602.30us\", \"mean\": \"273.38us\", \"calls\": 90}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"96.91us\", \"mean\": \"201.30us\", \"calls\": 20}, \"rewarder.sleep\": {\"std\": \"2.79ms\", \"mean\": \"13.94ms\", \"calls\": 208}, \"rewarder.compute_reward\": {\"std\": \"20.28ms\", \"mean\": \"7.67ms\", \"calls\": 230}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"17.48ms\", \"mean\": \"67.39ms\", \"calls\": 20}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.61512176551145, \"mean\": 0.43913043478260905, \"calls\": 230}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 70}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 70}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 90}} (export_time=540.73us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:50,121] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1957 bytes>', 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:50,156] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=21.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=167472.2 vnc_pixels_ps[total]=97957.2 reward_lag=None rewarder_message_lag=None fps=51.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [Sun Jan 15 16:00:50 UTC 2017] [/usr/local/bin/sudoable-env-setup] Disabling outbound network traffic for none\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:50,193] [INFO:root] [Rewarder] Rewarder fell behind by 0.12488341331481934s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [init] [2017-01-15 16:00:50,222] Launching system_diagnostics_logger.py, recorder_logdir=/tmp/demo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [init] [2017-01-15 16:00:50,230] Launching reward_recorder.py, recorder_logdir=/tmp/demo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [init] [2017-01-15 16:00:50,240] Launching vnc_recorder.py, recorder_logdir=/tmp/demo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [init] [2017-01-15 16:00:50,256] PID 56 launched with command ['sudo', '-H', '-u', 'nobody', 'DISPLAY=:0', 'DBUS_SESSION_BUS_ADDRESS=/dev/null', '/app/universe-envs/controlplane/bin/controlplane.py', '--rewarder-port=15901']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:50,341] [INFO:root] [Rewarder] Rewarder fell behind by 0.12621569633483887s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:50,378] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=20.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=213666.0 vnc_pixels_ps[total]=113413.7 reward_lag=None rewarder_message_lag=None fps=44.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:50,575] [INFO:universe.pyprofile] [pyprofile] period=5.00s timers={\"rewarder.frame\": {\"mean\": \"21.27ms\", \"std\": \"14.89ms\", \"calls\": 248}, \"rewarder.sleep\": {\"mean\": \"14.05ms\", \"std\": \"2.69ms\", \"calls\": 230}, \"reward.parsing.score\": {\"mean\": \"11.15ms\", \"std\": \"26.17ms\", \"calls\": 96}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"226.07us\", \"std\": \"340.07us\", \"calls\": 96}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"155.04us\", \"std\": \"36.16us\", \"calls\": 14}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"73.00ms\", \"std\": \"21.43ms\", \"calls\": 13}, \"rewarder.sleep.missed\": {\"mean\": \"47.36ms\", \"std\": \"32.29ms\", \"calls\": 18}, \"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"290.92us\", \"std\": \"750.45us\", \"calls\": 96}, \"reward.parsing.gameover\": {\"mean\": \"780.77us\", \"std\": \"2.02ms\", \"calls\": 96}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"653.89us\", \"std\": \"1.91ms\", \"calls\": 248}, \"rewarder.compute_reward\": {\"mean\": \"5.72ms\", \"std\": \"17.95ms\", \"calls\": 248}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.4354838709677419, \"std\": 0.5933768795599395, \"calls\": 248}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 82}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 83}} gauges={\"reward_parser.score.last_score\": {\"value\": 2954.0, \"mean\": 2954.0, \"std\": 0.0, \"calls\": 96}} (export_time=552.18us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:50,576] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.00s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<1960 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:50,717] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"rewarder.compute_reward\": {\"std\": \"17.91ms\", \"calls\": 252, \"mean\": \"5.60ms\"}, \"rewarder.sleep.missed\": {\"std\": \"30.03ms\", \"calls\": 14, \"mean\": \"48.90ms\"}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"213.61us\", \"calls\": 93, \"mean\": \"200.00us\"}, \"reward.parsing.gameover\": {\"std\": \"1.17ms\", \"calls\": 93, \"mean\": \"703.52us\"}, \"rewarder.frame\": {\"std\": \"13.13ms\", \"calls\": 252, \"mean\": \"20.52ms\"}, \"rewarder.sleep\": {\"std\": \"3.08ms\", \"calls\": 238, \"mean\": \"13.70ms\"}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"30.21ms\", \"calls\": 14, \"mean\": \"68.35ms\"}, \"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.42ms\", \"calls\": 252, \"mean\": \"593.22us\"}, \"reward.parsing.score\": {\"std\": \"27.20ms\", \"calls\": 93, \"mean\": \"11.52ms\"}, \"score.crop_cache.get.MatchImage\": {\"std\": \"864.65us\", \"calls\": 93, \"mean\": \"328.68us\"}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"73.24us\", \"calls\": 15, \"mean\": \"189.80us\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.580953624999057, \"calls\": 252, \"mean\": 0.40476190476190477}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"calls\": 78, \"mean\": 1.0}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"calls\": 79, \"mean\": 1.0}} gauges={\"reward_parser.score.last_score\": {\"std\": 0.0, \"value\": 2954.0, \"calls\": 93, \"mean\": 2954.0}} (export_time=496.15us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:50,718] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.01s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 1840, 'rewarder.profile': '<1962 bytes>', 'rewarder.vnc.updates.bytes': 5540, 'rewarder.vnc.updates.n': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:50,721] [INFO:root] [Rewarder] Rewarder fell behind by 0.12269330024719238s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [Sun Jan 15 16:00:50 UTC 2017] Waiting for /tmp/.X11-unix/X0 to be created (try 2/10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:50,941] [INFO:root] [Rewarder] Rewarder fell behind by 0.15910649299621582s from target; losing 9 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:50,981] Remote closed: address=localhost:5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:50,984] Remote closed: address=localhost:15905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-15 17:00:50,992] At least one sockets was closed by the remote. Sleeping 1s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Xvnc TigerVNC 1.7.0 - built Sep  8 2016 10:39:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Copyright (C) 1999-2016 TigerVNC Team and many others (see README.txt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] See http://www.tigervnc.org for information on TigerVNC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Underlying X server release 11400000, The X.Org Foundation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension VNC-EXTENSION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension Generic Event Extension\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension SHAPE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension MIT-SHM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension XInputExtension\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension XTEST\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension BIG-REQUESTS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension SYNC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension XKEYBOARD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension XC-MISC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension XINERAMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension XFIXES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension RENDER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension RANDR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension COMPOSITE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension DAMAGE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension MIT-SCREEN-SAVER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension DOUBLE-BUFFER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension RECORD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension DPMS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension X-Resource\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension XVideo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension XVideo-MotionCompensation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Initializing built-in extension GLX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] Sun Jan 15 16:00:51 2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc]  vncext:      VNC extension running!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc]  vncext:      Listening for VNC connections on all interface(s), port 5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc]  vncext:      created VNC server for screen 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:51,335] [INFO:root] [Rewarder] Rewarder fell behind by 0.10623764991760254s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:51,500] [INFO:root] [Rewarder] Rewarder fell behind by 0.14433693885803223s from target; losing 8 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/Type1/, removing from list!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/75dpi/, removing from list!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [tigervnc] [dix] Could not init font path element /usr/share/fonts/X11/100dpi/, removing from list!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:51,569] [INFO:root] [Rewarder] Rewarder fell behind by 0.16079473495483398s from target; losing 9 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:51,587] [INFO:root] [Rewarder] Rewarder fell behind by 0.22686529159545898s from target; losing 13 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:51,977] [INFO:root] [Rewarder] Rewarder fell behind by 0.13585281372070312s from target; losing 8 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:52,033] [INFO:root] [Rewarder] Rewarder fell behind by 0.13254022598266602s from target; losing 7 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-IKNb0S-0 |\u001b[0m [2017-01-15 16:00:52,524] [INFO:root] [Rewarder] Rewarder fell behind by 0.10090184211730957s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:52,844] [INFO:universe.pyprofile] [pyprofile] period=5.02s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"814.44us\", \"calls\": 301, \"mean\": \"322.49us\"}, \"rewarder.sleep\": {\"std\": \"1.24ms\", \"calls\": 301, \"mean\": \"15.59ms\"}, \"rewarder.compute_reward\": {\"std\": \"856.25us\", \"calls\": 301, \"mean\": \"613.54us\"}, \"rewarder.frame\": {\"std\": \"793.42us\", \"calls\": 301, \"mean\": \"17.01ms\"}} counters={\"agent_conn.reward\": {\"std\": 0, \"calls\": 1, \"mean\": 0.0}, \"reward.vnc.updates.n\": {\"std\": 0.0, \"calls\": 301, \"mean\": 0.0}} gauges={} (export_time=262.02us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-MOdcjs-0 |\u001b[0m [init] [2017-01-15 16:00:52,845] init detected end of child process 20 with exit code 0, not killed by signal\n\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:52,845] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0 reward_min=0 reward_max=0 done=False info={'rewarder.vnc.updates.bytes': 0, 'rewarder.vnc.updates.pixels': 0, 'rewarder.vnc.updates.n': 0, 'rewarder.profile': '<755 bytes>'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:52,900] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"score.crop_cache.get.OCRScorerV0\": {\"mean\": \"216.35us\", \"std\": \"301.86us\", \"calls\": 90}, \"rewarder.sleep\": {\"mean\": \"13.91ms\", \"std\": \"2.70ms\", \"calls\": 236}, \"score.crop_cache.get.MatchImage\": {\"mean\": \"230.01us\", \"std\": \"239.91us\", \"calls\": 90}, \"reward.parsing.score\": {\"mean\": \"11.63ms\", \"std\": \"29.83ms\", \"calls\": 90}, \"vnc_env.VNCEnv.vnc_session.step\": {\"mean\": \"497.52us\", \"std\": \"1.21ms\", \"calls\": 250}, \"reward.parsing.gameover\": {\"mean\": \"712.76us\", \"std\": \"1.08ms\", \"calls\": 90}, \"score.crop_cache.readthrough.MatchImage\": {\"mean\": \"179.79us\", \"std\": \"29.75us\", \"calls\": 12}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"mean\": \"78.75ms\", \"std\": \"37.14ms\", \"calls\": 12}, \"rewarder.sleep.missed\": {\"mean\": \"60.27ms\", \"std\": \"37.98ms\", \"calls\": 14}, \"rewarder.frame\": {\"mean\": \"21.28ms\", \"std\": \"16.42ms\", \"calls\": 250}, \"rewarder.compute_reward\": {\"mean\": \"5.54ms\", \"std\": \"19.15ms\", \"calls\": 250}} counters={\"agent_conn.reward\": {\"mean\": 0.0, \"std\": 0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"mean\": 0.3920000000000001, \"std\": 0.5509539007968025, \"calls\": 250}, \"score.crop_cache.hit.MatchImage\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 78}, \"score.crop_cache.hit.OCRScorerV0\": {\"mean\": 1.0, \"std\": 0.0, \"calls\": 78}} gauges={\"reward_parser.score.last_score\": {\"calls\": 90, \"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0}} (export_time=532.39us)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:52,913] [INFO:universe.rewarder.remote] [Rewarder] Over past 5.02s, sent 1 reward messages to agent: reward=0.0 reward_min=0.0 reward_max=0.0 done=False info={'rewarder.vnc.updates.pixels': 1840, 'rewarder.profile': '<1957 bytes>', 'rewarder.vnc.updates.n': 1, 'rewarder.vnc.updates.bytes': 5540}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:52,967] [INFO:universe.wrappers.logger] Stats for the past 5.01s: vnc_updates_ps=19.4 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=155365.4 vnc_pixels_ps[total]=95107.4 reward_lag=None rewarder_message_lag=None fps=49.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-uvabYn-0 |\u001b[0m [2017-01-15 16:00:53,345] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=0.0 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=0.0 vnc_pixels_ps[total]=0.0 reward_lag=None rewarder_message_lag=None fps=60.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-SO2WRJ-0 |\u001b[0m [2017-01-15 16:00:53,459] [INFO:root] [Rewarder] Rewarder fell behind by 0.1043400764465332s from target; losing 6 frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-zJz5ef-0 |\u001b[0m [2017-01-15 16:00:55,017] [INFO:universe.wrappers.logger] Stats for the past 5.02s: vnc_updates_ps=18.1 n=1 reaction_time=None observation_lag=None action_lag=None reward_ps=0.0 reward_total=0.0 vnc_bytes_ps[total]=172880.6 vnc_pixels_ps[total]=99807.8 reward_lag=None rewarder_message_lag=None fps=45.25\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Not all servers came up within 24s: [('rewarder', 'localhost:15905'), ('vnc', 'localhost:5905')]",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9d0da0fa1b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flashgames.DuskDrive-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# automatically creates a local docker container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mobservation_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/core.pyc\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# It can be confusing if you have the wrong environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/vectorized/core.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Did not set self.env.n: self.n={} self.env={} self={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/core.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/core.pyc\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# It can be confusing if you have the wrong environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/wrappers/render.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'render.modes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/vectorized/core.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Did not set self.env.n: self.n={} self.env={} self={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/core.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/core.pyc\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# It can be confusing if you have the wrong environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/wrappers/throttle.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, skip_metadata, fps, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mThrottle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video.frames_per_second'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/vectorized/core.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Did not set self.env.n: self.n={} self.env={} self={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/core.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/core.pyc\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# It can be confusing if you have the wrong environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/envs/vnc_env.pyc\u001b[0m in \u001b[0;36m_configure\u001b[0;34m(self, remotes, client_id, start_timeout, docker_image, ignore_clock_skew, disable_action_probes, vnc_driver, vnc_kwargs, rewarder_driver, replace_on_crash, allocate_sync, observer, api_key, record)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mremotes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0muse_recorder_ports\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/remotes/build.pyc\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(client_id, remotes, runtime, start_timeout, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mstart_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reuse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         ), n\n\u001b[1;32m     21\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mremotes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vnc://'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/remotes/docker_remote.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, runtime, n, reuse, start_timeout)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mstart_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mallocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/remotes/docker_remote.pyc\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhealthcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/remotes/docker_remote.pyc\u001b[0m in \u001b[0;36mhealthcheck\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m'{}:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massigner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvnc_port\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m'{}:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massigner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewarder_port\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mstart_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/remotes/healthcheck.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(vnc_addresses, rewarder_addresses, timeout, start_timeout)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvnc_addresses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewarder_addresses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mhealthcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHealthcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvnc_addresses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewarder_addresses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mhealthcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhost_port\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jana/universe/universe/remotes/healthcheck.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not all servers came up within {}s: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mError\u001b[0m: Not all servers came up within 24s: [('rewarder', 'localhost:15905'), ('vnc', 'localhost:5905')]"
     ],
     "output_type": "error"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muniverse-bBjNgN-0 |\u001b[0m [2017-01-15 16:00:55,131] [INFO:universe.pyprofile] [pyprofile] period=5.01s timers={\"vnc_env.VNCEnv.vnc_session.step\": {\"std\": \"1.77ms\", \"mean\": \"641.08us\", \"calls\": 231}, \"rewarder.frame\": {\"std\": \"22.42ms\", \"mean\": \"23.16ms\", \"calls\": 231}, \"reward.parsing.gameover\": {\"std\": \"1.17ms\", \"mean\": \"861.09us\", \"calls\": 78}, \"rewarder.sleep.missed\": {\"std\": \"53.14ms\", \"mean\": \"60.64ms\", \"calls\": 19}, \"reward.parsing.score\": {\"std\": \"40.24ms\", \"mean\": \"17.36ms\", \"calls\": 78}, \"score.crop_cache.get.OCRScorerV0\": {\"std\": \"479.13us\", \"mean\": \"296.01us\", \"calls\": 78}, \"score.crop_cache.get.MatchImage\": {\"std\": \"780.62us\", \"mean\": \"427.22us\", \"calls\": 78}, \"score.crop_cache.readthrough.MatchImage\": {\"std\": \"61.72us\", \"mean\": \"205.02us\", \"calls\": 13}, \"rewarder.sleep\": {\"std\": \"2.79ms\", \"mean\": \"13.58ms\", \"calls\": 212}, \"rewarder.compute_reward\": {\"std\": \"24.87ms\", \"mean\": \"7.50ms\", \"calls\": 231}, \"score.crop_cache.readthrough.OCRScorerV0\": {\"std\": \"40.77ms\", \"mean\": \"98.28ms\", \"calls\": 13}} counters={\"agent_conn.reward\": {\"std\": 0, \"mean\": 0.0, \"calls\": 1}, \"reward.vnc.updates.n\": {\"std\": 0.5334650693692643, \"mean\": 0.3636363636363637, \"calls\": 231}, \"score.crop_cache.hit.MatchImage\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 65}, \"score.crop_cache.hit.OCRScorerV0\": {\"std\": 0.0, \"mean\": 1.0, \"calls\": 65}} gauges={\"reward_parser.score.last_score\": {\"mean\": 2954.0, \"std\": 0.0, \"value\": 2954.0, \"calls\": 78}} (export_time=376.70us)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import universe  # register the universe environments\n",
    "from universe.wrappers import action_space\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('flashgames.DuskDrive-v0')\n",
    "env.configure(remotes=1)  # automatically creates a local docker container\n",
    "observation_n = env.reset()\n",
    "\n",
    "#define actions for slither\n",
    "#actions = [act for act in action_space.slither_vnc()]\n",
    "actions = [('KeyEvent','ArrowUp',True)]\n",
    "\n",
    "observation_n, reward_n, done_n, info = env.step([actions])\n",
    "print \"OBSERVATION::::::::::\", observation_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(object):\n",
    "    \n",
    "    def __init__(self, img_x, img_y, channels = 1, action_num = 3, batch_size = None):\n",
    "        self.IMG_X = img_x\n",
    "        self.IMG_Y = img_y\n",
    "        self.CHANNELS = channels\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.ACTION_NUM = action_num\n",
    "        self.y_conv = None\n",
    "        self.x = None\n",
    "        self.rewardPlusQ = None\n",
    "        self.train_step = None\n",
    "        \n",
    "    def build(self):\n",
    "        # Create the model\n",
    "        self.x = tf.placeholder(tf.float32, [self.BATCH_SIZE, self.IMG_X, self.IMG_Y, self.CHANNELS])\n",
    "        \n",
    "        #TODO: make this dynamic\n",
    "        W_conv1 = weight_variable([5, 5, self.CHANNELS, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(self.x, W_conv1) + b_conv1)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "        \n",
    "        \n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        \n",
    "        W_fc1 = weight_variable([self.IMG_Y/4 * self.IMG_X/4 * 64, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        \n",
    "        W_fc2 = weight_variable([1024, self.ACTION_NUM])\n",
    "        b_fc2 = bias_variable([self.ACTION_NUM])\n",
    "        self.y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "        # Define loss and optimizer\n",
    "        \n",
    "        self.rewardPlusQ = tf.placeholder(tf.float32, [self.BATCH_SIZE, self.ACTION_NUM])\n",
    "        loss = tf.reduce_mean(tf.squared_difference(self.rewardPlusQ, self.y_conv))\n",
    "        #cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "        self.train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "        \n",
    "        \n",
    "        #sess = tf.InteractiveSession()\n",
    "        #tf.global_variables_initializer().run()\n",
    "        \n",
    "        \n",
    "    @staticmethod  \n",
    "    def conv2d(x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    @staticmethod\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    @staticmethod\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QFunc(object):\n",
    "    def __init__(self, net, session, action_num):\n",
    "        self.replayMemory = []\n",
    "        self.epsilon = 0.01\n",
    "        self.ACTION_NUM = action_num\n",
    "        self.net = net\n",
    "        self.session = session\n",
    "        self.BATCH_SIZE = 16\n",
    "    \n",
    "    #returns Q values for each available action\n",
    "    def getQValues(self, inputFrames):\n",
    "        return self.session.run(self.net.y_conv, feed_dict = {self.net.x:inputFrames})\n",
    "    \n",
    "    def train(self):\n",
    "        #take n tuples (state,action,reward,nextState) from replay memory\n",
    "        if(len(self.replayMemory) == 0):\n",
    "            return\n",
    "        replayTuples = np.random.choice(self.replayMemory, self.BATCH_SIZE)\n",
    "        \n",
    "        #for each tuple calculate bestActionMaxReward = reward + lr*max(getQValues(nextState))\n",
    "        nextStates = replayTuples[:,3]\n",
    "        qVals = self.getQValues(nextStates)\n",
    "        rewardPlusQ = np.zeros((self.BATCH_SIZE, len(self.ACTION_NUM)))\n",
    "        for i in range(self.BATCH_SIZE):\n",
    "            rewardPlusQ[i,replayTuples[i,1]]= replayTuples[:,2] + self.epsilon * np.max(qVals[i])        \n",
    "        \n",
    "        #backpropagation with loss = bestActionMaxReward - getQValue(state)[action]\n",
    "        self.session.run(self.net.train_step, \n",
    "                         feed_dict = {self.net.rewardPlusQ:rewardPlusQ, self.net.x:replayTuples[:,0]})\n",
    "    \n",
    "    def addToReplay(self, stateTuple):\n",
    "        self.replayMemory.append(stateTuple)\n",
    "    \n",
    "    def test(self, inputFrames):\n",
    "        pass\n",
    "    \n",
    "    def react(self, observation):\n",
    "        action = None\n",
    "        if(random.random() >= self.epsilon):\n",
    "            action = np.argmax(self.getQValues(observation.state))\n",
    "        else:\n",
    "            action = random.randint(0,self.ACTION_NUM)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet = QNet()\n",
    "Q = QFunc()\n",
    "\n",
    "while True:\n",
    "    #for each frame in observation let the network react with an action\n",
    "    actions_n = [actions[Q.react(ob)] for ob in observation_n]\n",
    "    #the observation of this step\n",
    "    oldObservation_n = observation_n\n",
    "    #the next observation and the rewards gotten from our previous actions\n",
    "    observation_n, reward_n, done_n, info = env.step(actions_n)\n",
    "\n",
    "    #now these experiences must be saved as replay memories\n",
    "    for i in range(len(oldObservation_n)):\n",
    "        Q.addToReplay((oldObservation_n[i], actions_n[i], reward_n[i],observation_n[i]))\n",
    "\n",
    "    Q.train()\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}